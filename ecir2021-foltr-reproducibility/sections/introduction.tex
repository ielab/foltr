\section{Introduction}

Online learning to rank (OLTR) exploits users queries and interactions with search engine result pages (SERPs) to iteratively train and update a ranker in  production~\cite{bibid}. In particular, OLTR relies on implicit user feedback from interactions on SERPs, e.g., clicks, rather than editorial relevance labels. 
Several methods for OLTR exist that attempt to address the specific challenges of online learning~\cite{bibid}: from making sense of the implicit feedback, to exploring the space of feature weights, accounting for biases in the click signal, reducing the impact of the online learning process on user experience, among others. 

An aspect that has not been received wide attention in OLTR is how the privacy of users could be guaranteed. Current OLTR methods in fact assume that a central server collects all queries and interactions of all users of the search system, and it is this central server that is responsible for the indexing of the collection, the training of the ranker and the production of the SERPs. A recent work by Kharitonov, however, has attempted to provide a mechanism for OLTR that preserves the privacy of users~\cite{kharitonov2019federated}. The method, called FOLTR-ES, relies on the federated learning paradigm~\cite{bibid}, in which data (collection, queries, interactions) is maintained at each client's side along with a copy of the ranker, and updates to the rankers that are learned from the interaction on the client side are shared to the central server, which is responsible for aggregating the update signal from clients and propagate the aggregated ranker update. In this specific case, all users observe and act on the same feature space; each user however retains control of their own data, which includes the collection, the queries and the interactions. FOLTR-ES uses evolutionary strategies akin to those in genetic algorithms to make client rankers explore the feature space, and a parametric privacy preserving mechanism to further anonymise the feedback signal that is shared by clients to the central server.  


This paper aims to replicate and then reproduce the experiments from the original work of Kharitonov~\cite{kharitonov2019federated}, investigating the effect different configurations of that federated OLTR method have on effectiveness and user experience, extending and generalising its evaluation to different settings commonly used in OLTR and to different collections. Specifically, we address the following research questions:

\begin{itemize}
	\item[\bf RQ1:] \textit{Does the performance of FOLTR-ES generalise beyond the MQ2007/2008 datasets?} The original method was only evaluated using MQ2007/2008~\cite{DBLP:journals/corr/QinL13}, while current OLTR practice is to use larger datasets that are feature richer and that contain typical web results.
	\item[\bf RQ2:] \textit{How does the number of clients involved in FOLTR-ES affect its performance?} FOLTR-ES was previously evaluated using a set number of clients involved in the federated OLTR process ($n=2,000$), and it was left unclear whether considering more or less client would impact performance.
	\item[\bf RQ3:] \textit{How does FOLTR-ES compare with current state-of-the-art OLTR methods?} Compared to OLTR methods, FOLTR-ES preserves user privacy, but it is unclear to what expense in terms of search performance: the original work compared FOLTR-ES to rankers in non-federated settings, but the rankers used in there were not the current state-of-the-art in OLTR.
	\item[\bf RQ4:] \textit{How does FOLTR-ES performance generalise to the evaluation settings commonly used for OLTR evaluation, i.e. measuring offline and online performance, with respect to nDCG and with relevance labels?} The original evaluation of FOLTR-ES considered an unusual setting for OLTR, consisting of using MaxRR~\cite{radlinski2008learning} as evaluation measure in place of nDCG, computed on simulated clicks instead of on relevance labels.
\end{itemize}

The results of our empirical investigation of FOLTR-ES help understanding the specific settings in which this technique works, and the trade-offs between user privacy and search performance (in terms of effectiveness and user experience). They also unveil that more work is require to devise effective federated methods for OLTR that can guarantee some degree of user privacy without sensibly compromising search performance.